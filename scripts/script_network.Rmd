---
title: "script_network"
author: "Julian Mittmann-Goetsch"
date: "2025-02-04"
output: html_document
---
# Versionlog
## Version 1.0: Basic script for network analysis (04.02.2025)

# Step 1: Prepare session and load data
## Step 1a: Install necessary packages
```{r}
library(devtools)
options("install.lock"=FALSE) 
#install_github("zdk123/SpiecEasi")
install.packages("cooccur")
install.packages("igraph")


library(devtools)
install_github("zdk123/SpiecEasi")
library(SpiecEasi)


# Ju et al. 2014
install.packages(c("vegan", "igraph", "Hmisc"))
library(vegan)
library(igraph)
library(Hmisc)
```

## Step 1b: Load necessary packages
```{r}
library(tidyverse)
library(ggplot2)
library(phyloseq)

library(SpiecEasi)

library(cooccur)
library(igraph)
```

## Step 1c: Load sequencing data
```{r}
tab_rare <- read.csv("./table_ASV_filtered_rarefied_5000.csv", dec = ",", sep = ";")
df_metadata <-  read.delim("./metadata.txt", dec = ".", sep= "\t")
```

## Step 1d: Define plot theme
```{r message=FALSE, warning=FALSE}
# Creates a theme for all plots in this study 
theme_JM <- theme(axis.title.x        = element_text(colour = "black", size = 12, face = "bold"),
                   axis.text.x        = element_text(colour = "black", size = 12, face = "bold"), 
                   axis.title.y       = element_text(colour = "black", size = 12, face = "bold"),
                   axis.text.y        = element_text(colour = "black", size = 12, face = "bold"), 
                   legend.title       = element_text(colour = "black", size = 12, face = "bold"),
                   legend.text        = element_text(colour = "black", size = 12, face = "bold"), 
                   legend.position    = "top",
                   panel.background   = element_blank(), panel.border = element_rect(colour = "black", fill = NA, size = 1.2),
                   legend.key         = element_blank(),
                   strip.text.x       = element_text(colour = "black", size = 12, face = "bold"),
                   strip.text.y       = element_text(colour = "black", size = 12, face = "bold"))
```


# Step 2: SpiecEasi Co-occurence network
## Step 2a: SpiecEasi with phyloseq object
```{r}
# Using the phyloseq object from the main script with the rarefied data
stat_se_coocurrence <- spiec.easi(ps_rare, method='mb', lambda.min.ratio=1e-2,
                           nlambda=20, pulsar.params=list(rep.num=50))
stat_se_coocurrence_mb <- adj2igraph(getRefit(stat_se_coocurrence),  vertex.attr=list(name=taxa_names(ps_rare)))
plot_network(stat_se_coocurrence_mb, ps_rare, type='taxa', color="Rank3")
```






## Co-occurence following Ju et al. 2014
# Script 1
```{r}
matrix <- tab_rare

matrix <- matrix[, !colnames(matrix) %in% c("X136", "X137", "X138", "X139")]
matrix <- matrix[, 1:(ncol(matrix) - 6)]

co_occurrence_network<-function(matrix,cor.cutoff,p.cutoff){
  
  matrix1<-matrix
  matrix1[matrix1>0]<-1
  
  #correlation analysis based on spearman's co-efficient
  matrix.dist<-rcorr(t(matrix),type="spearman")
  ###matrix.dist<-rcorr(t(matrix),type="pearson")
  matrix.cor<-matrix.dist$r
  matrix.cor.p<-matrix.dist$P
  
  #Multiple testing correction using Benjamini-Hochberg standard false discovery rate correction ("FDR-BH")
  matrix.cor.p <- p.adjust(matrix.cor.p, method="BH")
  
  #1.Consider positive cooccurence at given coefficient (cor.cutoff) and p-value cutoffs
  matrix.cor1<-matrix.cor
  matrix.cor1.p<-matrix.cor.p
  matrix.cor1[which(matrix.cor1 <= cor.cutoff)]=0
  matrix.cor1[which(matrix.cor1.p>p.cutoff)]=0
  # delete those rows and columns with sum = 0
  matrix.cor1<-matrix.cor1[which(rowSums(matrix.cor1)!=1),]
  matrix.cor1<-matrix.cor1[,which(colSums(matrix.cor1)!=0)]
  
  #2.Consider netagive cooccurence at given coefficient (-cor.cutoff) and p-value cutoffs
  ###matrix.cor2<-matrix.cor
  ###matrix.cor2.p<-matrix.cor.p
  ###matrix.cor2[which(matrix.cor2 > (-cor.cutoff))]=0
  ###matrix.cor2[which(matrix.cor2.p>p.cutoff)]=0
  # delete those rows and columns with sum = 0
  ###matrix.cor2<-matrix.cor2[which(rowSums(matrix.cor2)!=1),]
  ###matrix.cor2<-matrix.cor2[,which(colSums(matrix.cor2)!=0)]
  
  #3.Consider both positive and netagive cooccurence at given coefficient (cor.cutoff) and p-value cutoffs
  matrix.cor3<-matrix.cor
  matrix.cor3.p<-matrix.cor.p
  matrix.cor3[which(matrix.cor3>=(-cor.cutoff) & matrix.cor3 <= cor.cutoff)]=0
  matrix.cor3[which(matrix.cor3.p>p.cutoff)]=0
  
  # delete those rows and columns with sum = 0
  matrix.cor3<-matrix.cor3[which(rowSums(matrix.cor3)!=1),]
  matrix.cor3<-matrix.cor3[,which(colSums(matrix.cor3)!=0)]
  
  # generate graph using igraph
  g1<-graph.adjacency(matrix.cor1,weight=T,mode="undirected")
  g1<-simplify(g1)
  V(g1)$label <- V(g1)$name
  V(g1)$degree <- degree(g1)
  
  ###g2<-graph.adjacency(matrix.cor2,weight=T,mode="undirected")
  ###g2<-simplify(g2)
  ###V(g2)$label <- V(g2)$name
  ###V(g2)$degree <- degree(g2)
  
  g3<-graph.adjacency(matrix.cor3,weight=T,mode="undirected")
  g3<-simplify(g3)
  V(g3)$label <- V(g3)$name
  V(g3)$degree <- degree(g3)
  
  # append the output into results
  result<-list()
  result$matrix.cor<-matrix.cor
  result$matrix.cor.p<-matrix.cor.p
  
  result$matrix.cor1<-matrix.cor1
  result$graph1<-g1
  
  ###result$matrix.cor2<-matrix.cor2
  ###result$graph2<-g2
  
  result$matrix.cor3<-matrix.cor3
  result$graph3<-g3
  return(result)
}
```

# Script 2
```{r}
# Co-occurrence-network-analysis
################## OTU filtering, network generation, topological analysis and export OTU table ###############################
#library(igraph)
#library(Hmisc)



# Co-occurrence-network-analysis
library(igraph)
library(Hmisc)

Abu <- as.matrix(matrix)

### 1. [Filtering OTUs by occurrence frequency](pplx://action/followup)
table <- Abu
table[table > 0] <- 1
table.generalist <- Abu[which(rowSums(table) >= 12), ]
Abu <- table.generalist

### 2. [Creating gml files of network](pplx://action/followup)
pattern <- co_occurrence_network(Abu, 0.6, 0.01)  # cutoffs for correlation coefficient and P-value

write_graph(pattern$graph1, 'Pos0.6-NW.gml', format = 'gml')    # network file for positive association
write_graph(pattern$graph3, 'PosNeg0.6-NW.gml', format = 'gml') # network file for all association

### 3. [Calculating network topological properties](pplx://action/followup)
g <- pattern$graph1   # positive network

c <- cluster_walktrap(g)
# Global topological features
md <- modularity(g, membership(c), weights = NULL)
cc <- transitivity(g, vids = NULL, weights = NULL)
spl <- mean_distance(g, directed = FALSE, unconnected = TRUE)
gd  <- edge_density(g, loops = FALSE)
nd  <- diameter(g, directed = FALSE, unconnected = TRUE, weights = NA)

node.degree <- degree(g, v = V(g), mode = "all")
ad  <- mean(node.degree)

e <- ecount(g)
v <- vcount(g)
global.topology <- data.frame(e, v, cc, spl, md, gd, nd, ad)
write.csv(global.topology, file = "Pos0.6-NW-global.topology.csv")

# Node topological features
betweenness.centrality <- betweenness(g, v = V(g), 
                                      directed = FALSE, weights = NA,
                                      normalized = FALSE)

closeness.centrality <- closeness(g, vids = V(g),
                                  weights = NA, normalized = FALSE)

eigenvector.centrality <- eigen_centrality(g, directed = FALSE, weights = NA)$vector

node.topology <- data.frame(node.degree, betweenness.centrality, 
                            closeness.centrality, eigenvector.centrality)

write.csv(node.topology, file = "Pos0.6-NW-node.topology.csv")

# Ploting node degreee distribution in a log-log plot
degree.df <- data.frame(table(degree=factor(node.degree, levels=seq_len(max(node.degree)))))
degree.df$degree <- as.numeric(as.character(degree.df$degree))

#4. Creating an abundance table for OTUs present in the positive and negative network
my.list1 <- row.names(pattern$matrix.cor1)
###my.list2 <- row.names(pattern$matrix.cor2)

logical1 <- row.names(Abu)  %in% my.list1
###logical2 <- row.names(Abu)  %in% my.list2

tab.subset1 <- subset(Abu,logical1)
###tab.subset2 <- subset(Abu,logical2)

write.table(tab.subset1,'Pos0.6-NW.txt',sep="\t")
###write.table(tab.subset2,'Neg0.6-NW.txt',sep="\t")
```

#Script 3
```{r}

```

```{r}
library(vegan)

# Assuming df_asv_rare is your species-by-site matrix
c_score_result <- oecosimu(df_asv_rare, nestfun = nestedchecker, method = "swap", nsimul = 30000)

# Print the results
print(c_score_result)

```

```{r}
# Filter genera occurring in at least 20% of samples and with >2.5% total relative abundance
genera_prevalence <- apply(df_asv_rare > 0, 2, mean)
genera_abundance <- colSums(df_asv_rare) / sum(df_asv_rare)
filtered_genera <- names(genera_prevalence[genera_prevalence >= 0.2 & genera_abundance > 0.025])

filtered_data <- df_asv_rare[, filtered_genera]

# Calculate Spearman correlations
cor_matrix <- cor(filtered_data, method = "spearman")

# Filter genera based on prevalence and abundance
prevalence_threshold <- 0.2 * ncol(df_asv_rare)
abundance_threshold <- 0.025 * sum(colSums(df_asv_rare))
filtered_asv <- df_asv_rare[rowSums(df_asv_rare > 0) >= prevalence_threshold & 
                            rowSums(df_asv_rare) >= abundance_threshold, ]

# Calculate Spearman correlations
cor_matrix <- rcorr(t(filtered_asv), type = "spearman")

# Extract correlation coefficients and p-values
cor_coef <- cor_matrix$r
cor_pval <- cor_matrix$P

# Apply Benjamini-Hochberg correction
cor_pval_adj <- p.adjust(cor_pval, method = "BH")

# Create adjacency matrix for significant correlations
adj_matrix <- (abs(cor_coef) > 0.6) & (cor_pval_adj < 0.01)
diag(adj_matrix) <- 0

# Create igraph object
network <- graph_from_adjacency_matrix(adj_matrix, mode = "undirected", weighted = TRUE)

# Calculate network properties
avg_degree <- mean(degree(network))
node_density <- edge_density(network)
modularity <- modularity(cluster_louvain(network))
clustering_coef <- transitivity(network)
avg_path_length <- average.path.length(network)

# Print network properties
cat("Average Degree:", avg_degree, "\n")
cat("Node Density:", node_density, "\n")
cat("Modularity:", modularity, "\n")
cat("Clustering Coefficient:", clustering_coef, "\n")
cat("Average Path Length:", avg_path_length, "\n")

# Generate random networks for comparison
random_networks <- lapply(1:10000, function(i) {
  erdos.renyi.game(vcount(network), ecount(network), type = "gnm")
})

# Compare with random networks
random_properties <- sapply(random_networks, function(rn) {
  c(avg_degree = mean(degree(rn)),
    node_density = edge_density(rn),
    modularity = modularity(cluster_louvain(rn)),
    clustering_coef = transitivity(rn),
    avg_path_length = average.path.length(rn))
})

# Calculate p-values
p_values <- sapply(1:5, function(i) {
  sum(random_properties[i,] >= c(avg_degree, node_density, modularity, clustering_coef, avg_path_length)[i]) / 10000
})

names(p_values) <- c("Average Degree", "Node Density", "Modularity", "Clustering Coefficient", "Average Path Length")
print(p_values)
```

```{r}
# Convert your ASV table to presence/absence
pa_matrix <- ifelse(df_asv_rare > 0, 1, 0)

# Perform C-score analysis
c_score_result <- oecosimu(pa_matrix, nestfun = nestedchecker, method = "quasiswap", 
                           nsimul = 30000, alternative = "greater")

# Print the results
print(c_score_result)
```


###
```{r}
# Set row names to sample_name and remove the sample_name column
rownames(df_asv_rare) <- df_asv_rare$sample_name
df_asv_rare <- df_asv_rare[, -1]

# Ensure all data is numeric
df_asv_rare <- as.data.frame(lapply(df_asv_rare, as.numeric))

# Transpose the data for cooccur function
df_asv_rare_t <- t(df_asv_rare)
```

```{r}
cooc_result <- cooccur(df_asv_rare_t, spp_names = TRUE)
plot(cooc_result)
```

```{r}
# Treatment subsets
df_asv_rare_ambient <- df_asv_rare[df_metadata$Treatment == 'ambient', ]
df_asv_rare_1.5 <- df_asv_rare[df_metadata$Treatment == '1.5', ]
df_asv_rare_3 <- df_asv_rare[df_metadata$Treatment == '3', ]

cooc_ambient <- cooccur(t(df_asv_rare_ambient), spp_names = TRUE)
cooc_1.5 <- cooccur(t(df_asv_rare_1.5), spp_names = TRUE)
cooc_3 <- cooccur(t(df_asv_rare_3), spp_names = TRUE)

plot(cooc_ambient, main="Ambient Treatment")
plot(cooc_1.5, main="1.5 Treatment")
plot(cooc_3, main="3 Treatment")
```


## Step 1e: Modify asv table
```{r}
# Transpose table
df_asv_rare <- as.data.frame(t(tab_rare))

# Filter Mock samples 
df_asv_rare <- df_asv_rare %>%
  filter(!row.names(.) %in% c("X136", "X137", "X138", "X139", "Kingdom", "Phylum", "Class", "Order", "Family", "Genus")) %>%
  rownames_to_column("sample_name")

df_asv_rare[, -1] <- lapply(df_asv_rare[, -1], as.numeric)

df_asv_rare[, 2:17390] <- lapply(df_asv_rare[, 2:17390], as.numeric)

# Add metadata
df_asv_rare <- df_asv_rare %>%
  rownames_to_column("sample_name") %>%
  left_join(df_metadata, by = "sample_name") %>%
  column_to_rownames("sample_name")


```


# Step 2: Network Analysis
## Step 2a:
```{r}
df_asv_rare_t <- t(df_asv_rare)

cooc_sum <-cooccur(df_asv_rare_t, spp_names = T)

```



```{r}
# Load required libraries


# Assuming your phyloseq object is named 'ps'

# 1. Extract OTU table
otu_table <- as(otu_table(ps), "matrix")
otu_table <- t(otu_table)  # Transpose if necessary (samples as rows)

# 2. Filter low-abundance OTUs (optional, but recommended)
min_prevalence <- 0.1  # Present in at least 10% of samples
min_abundance <- 10    # At least 10 reads in total
otu_table_filtered <- otu_table[, colSums(otu_table > 0) >= nrow(otu_table) * min_prevalence]
otu_table_filtered <- otu_table_filtered[, colSums(otu_table_filtered) >= min_abundance]

# 3. Calculate correlations (using SparCC method)
sparcc_results <- sparcc(otu_table_filtered)

# 4. Create network
corr_matrix <- sparcc_results$Cor
diag(corr_matrix) <- 0  # Remove self-correlations

# Set correlation threshold
corr_threshold <- 0.3
corr_matrix[abs(corr_matrix) < corr_threshold] <- 0

# Create graph
g <- graph_from_adjacency_matrix(corr_matrix, mode = "undirected", weighted = TRUE)

# 5. Calculate network properties
degree <- degree(g)
betweenness <- betweenness(g)
closeness <- closeness(g)

# 6. Visualize network
plot(g, vertex.size = 3, vertex.label = NA, edge.width = E(g)$weight)

# 7. Analyze by Treatment and Zone
sample_data <- as(sample_data(ps), "data.frame")

# Function to create subnetwork for a specific Treatment and Zone
create_subnetwork <- function(treatment, zone) {
    subset_samples <- sample_data$Treatment == treatment & sample_data$Zone == zone
    subset_otu <- otu_table_filtered[subset_samples, ]
    subset_sparcc <- sparcc(subset_otu)
    subset_corr <- subset_sparcc$Cor
    diag(subset_corr) <- 0
    subset_corr[abs(subset_corr) < corr_threshold] <- 0
    subset_g <- graph_from_adjacency_matrix(subset_corr, mode = "undirected", weighted = TRUE)
    return(subset_g)
}

# Create subnetworks for each Treatment-Zone combination
treatments <- unique(sample_data$Treatment)
zones <- unique(sample_data$Zone)

subnetworks <- list()
for (t in treatments) {
    for (z in zones) {
        subnetworks[[paste(t, z, sep = "_")]] <- create_subnetwork(t, z)
    }
}

# 8. Compare subnetworks
compare_networks <- function(g1, g2) {
    common_nodes <- intersect(V(g1)$name, V(g2)$name)
    jaccard <- length(common_nodes) / length(union(V(g1)$name, V(g2)$name))
    return(jaccard)
}

network_similarities <- matrix(NA, nrow = length(subnetworks), ncol = length(subnetworks))
rownames(network_similarities) <- names(subnetworks)
colnames(network_similarities) <- names(subnetworks)

for (i in 1:length(subnetworks)) {
    for (j in 1:length(subnetworks)) {
        network_similarities[i, j] <- compare_networks(subnetworks[[i]], subnetworks[[j]])
    }
}

# Visualize network similarities
heatmap(network_similarities, main = "Network Similarities across Treatments and Zones")

```

